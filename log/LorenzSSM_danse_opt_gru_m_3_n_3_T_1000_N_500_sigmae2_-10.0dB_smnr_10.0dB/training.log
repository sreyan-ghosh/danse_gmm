------------------------------ Training begins --------------------------------- 

Config: {'n_states': 3, 'n_obs': 3, 'mu_w': array([0., 0., 0.]), 'C_w': array([[22.80531504,  0.        ,  0.        ],
       [ 0.        , 22.80531504,  0.        ],
       [ 0.        ,  0.        , 22.80531504]]), 'H': array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]]), 'mu_x0': array([0., 0., 0.]), 'C_x0': array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]]), 'batch_size': 64, 'rnn_type': 'gru', 'device': device(type='cpu'), 'rnn_params_dict': {'gru': {'model_type': 'gru', 'input_size': 3, 'output_size': 3, 'n_hidden': 30, 'n_layers': 1, 'lr': 0.01, 'num_epochs': 2000, 'min_delta': 0.05, 'n_hidden_dense': 32, 'device': device(type='cpu')}, 'rnn': {'model_type': 'gru', 'input_size': 3, 'output_size': 3, 'n_hidden': 40, 'n_layers': 2, 'lr': 0.001, 'num_epochs': 300, 'min_delta': 0.001, 'n_hidden_dense': 32, 'device': device(type='cpu')}, 'lstm': {'model_type': 'lstm', 'input_size': 3, 'output_size': 3, 'n_hidden': 40, 'n_layers': 2, 'lr': 0.001, 'num_epochs': 300, 'min_delta': 0.001, 'n_hidden_dense': 32, 'device': device(type='cpu')}}} 

No. of trainable parameters: 4340

Epoch: 1/2000, Training NLL:6.949937900, Val. NLL:6.116657495, Val. MSE: 213.307325764, Time_Elapsed:2.9436 secs
Epoch: 50/2000, Training NLL:1.181499779, Val. NLL:1.180583835, Val. MSE: 4.330416231, Time_Elapsed:165.3155 secs
Epoch: 100/2000, Training NLL:1.177391609, Val. NLL:1.176308751, Val. MSE: 5.042596623, Time_Elapsed:341.9898 secs
Epoch: 150/2000, Training NLL:1.175660054, Val. NLL:1.178196073, Val. MSE: 4.679164609, Time_Elapsed:516.6199 secs
Epoch: 200/2000, Training NLL:1.175395648, Val. NLL:1.173059344, Val. MSE: 3.892138600, Time_Elapsed:695.7470 secs
Epoch: 250/2000, Training NLL:1.174623609, Val. NLL:1.173906207, Val. MSE: 3.899949699, Time_Elapsed:873.7868 secs
Epoch: 300/2000, Training NLL:1.174853206, Val. NLL:1.173469484, Val. MSE: 4.069236101, Time_Elapsed:1059.3415 secs
Epoch: 350/2000, Training NLL:1.173908114, Val. NLL:1.171990097, Val. MSE: 4.074127804, Time_Elapsed:1236.9157 secs
Epoch: 400/2000, Training NLL:1.174882988, Val. NLL:1.167257786, Val. MSE: 4.429304162, Time_Elapsed:1413.3877 secs
Epoch: 450/2000, Training NLL:1.173994700, Val. NLL:1.171058118, Val. MSE: 4.768131884, Time_Elapsed:1590.7138 secs
Epoch: 500/2000, Training NLL:1.174048046, Val. NLL:1.170171976, Val. MSE: 4.412312086, Time_Elapsed:1766.3979 secs
Epoch: 550/2000, Training NLL:1.173199336, Val. NLL:1.172508597, Val. MSE: 3.860538051, Time_Elapsed:1940.0774 secs
Epoch: 600/2000, Training NLL:1.173234940, Val. NLL:1.173302174, Val. MSE: 4.408430703, Time_Elapsed:2115.2724 secs
Epoch: 650/2000, Training NLL:1.175770462, Val. NLL:1.170352161, Val. MSE: 3.917345158, Time_Elapsed:2289.5217 secs
Consecutive iterations are:[669, 670, 671]
Exit and Convergence reached after 3 iterations for relative change in NLL below :0.05
Training convergence attained at Epoch: 671!

Saving the best model at epoch=671, with training loss=1.172893186410268, validation loss=1.171786367893219
------------------------------ Training ends --------------------------------- 

